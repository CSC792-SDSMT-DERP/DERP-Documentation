\documentclass{article}
\usepackage[margin=1in]{geometry}
\usepackage[utf8]{inputenc}
\usepackage{comment}
\usepackage{listings}
\usepackage{titlesec}       % Lines under Sections
\titleformat{\section}
  {\normalfont\Large\bfseries}{\thesection}{1em}{}[{\titlerule[0.8pt]}]

\usepackage{etoolbox}       % Because titlesec removes section numbering -_-
\makeatletter
\patchcmd{\ttlh@hang}{\parindent\z@}{\parindent\z@\leavevmode}{}{}
\patchcmd{\ttlh@hang}{\noindent}{}{}{}
\makeatother

\renewcommand\maketitle{}

% Give Table of Contents Hyperlinks
\usepackage{hyperref}
\hypersetup{
    colorlinks,
    citecolor=black,
    filecolor=black,
    linkcolor=black,
    urlcolor=blue
}
\pagenumbering{gobble}
% \pagenumbering{roman} % set the numbering style to lowercase letter

\title{\textbf{Dictation Evaluation Reddit Parser}}

\author{
Garcia, Benjamin \and
Lembke, Logan \and 
MacMillan, Kyle  \and 
Smith, Christopher \and 
Stelter, Andrew 
}
\date{September 21, 2018}


%\setcounter{secnumdepth}{4}

\titleformat{\paragraph}
{\normalfont\normalsize\bfseries}{\theparagraph}{1em}{}
\titlespacing*{\paragraph}
{0pt}{3.25ex plus 1ex minus .2ex}{1.5ex plus .2ex}

\begin{document}


\addcontentsline{toc}{section}{Title}
\maketitle %%TODO: maketitle doesn't seem to be working

\newpage
\tableofcontents
\addcontentsline{toc}{section}{Table of Contents}

\pagenumbering{roman}   % Set TOC page numbering to lowercase roman numerals



%%%%%%%%%%%%%%%%%%%%%%%%%%%% INTRO SECTION %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\hypersetup{
    colorlinks,
    citecolor=blue,
    filecolor=black,
    linkcolor=blue,
    urlcolor=blue
}
\pagenumbering{arabic}  % Set content page numbering to arabic numerals

\section{\textbf{Introduction to DERP}}

\setcounter{page}{1} % Set the page counter to 3
\href{https://gitlab.mcs.sdsmt.edu/7184015/DERP}{DERP}, the \textbf{D}ictation \textbf{E}valuation \textbf{R}eddit \textbf{P}arser, is a \href{https://en.wikipedia.org/wiki/Domain-specific_language}{DSL}(Domain Specific Language) for finding news information from multiple web sources simultaneously. The system was designed as part of a group project for South Dakota School of Mines \& Technology's Compilers course.

\subsection{What is DERP: Human Queries For a Digital World}\label{sec:whatisDERP}
Time is a resource that people regularly find themselves lacking, and many would agree it would be convenient to have an easy way to consume online news while doing daily tasks -- preparing and eating breakfast, taking a shower, getting dressed, or driving to work. We should be able to say to a phone, ``What's going on in the world today?'' and get a response containing relevant information that we care about; not just ``I'm sorry, I don't understand, `What's going on in the world today' ''. If we want news on a specific topic, such as Tesla, getting that information should be as easy as saying, ``What's in the news about Tesla?''. 

The formats used to present news are largely unchanged in recent years; sure, the internet provides a way for news to be shared, but we still have to hunt down the stories we want, whether we get them through a radio or television broadcast, an individual online or print article, or a newspaper. These formats are often quite rigid, giving us little control over what news we get, or so full of information that doesn't concern us that it can be difficult to know where to begin. One common solution used as a middle ground to these problems is aggregation sites such as \href{https://www.reddit.com}{Reddit}, \href{https://steemit.com/}{steemit}, \href{https://band.us/home}{band}, and \href{https://voat.co/}{voat} to name a \href{https://www.reddit.com/r/RedditAlternatives/comments/8585ox/list_of_active_reddit_alternatives/}{few}. While these sites in this category go a long way toward solving the problems presented, they often fall into the same traps: Lacking information users want or presenting so much information that it's difficult to wade through it all.

\subsection{DERP Origins}
In the fall of 2018 we were tasked with making a DSL for a class in compiler theory. A number of applications discussed by our team follow:
\begin{itemize}
    \item{Describe Constraints  to Generate something}
    \begin{itemize}
        \item{Floor Plans}
        \item{Workout Assistant}
        \item{Computer Part Picker}
    \end{itemize}
    \item{Perform a Task}
    \begin{itemize}
        \item{Robot "AI" Proposal by Dr. Hinker}
        \item{Simple Image Processing}
    \end{itemize}
    \item{Configure a Task}
    \begin{itemize}
        \item{News Reader}
        \item{SQL Helper}        
    \end{itemize}
\end{itemize}

We decided against a Constrain/Generate model because the ideas we came up with all required labeled data which we did not have access to, and we were not sure that we would be able to find or make sufficient data in a timely manner.

Creating a language to help perform a task seemed like a good idea at first, but we realized being reliant on some external item (a robot, in the case of Dr. Hinker's proposal) could hinder progress unnecessarily. We were also wary of working with a new, possibly unfinished, project and didn't know if we'd be walking into a well-documented, fully-defined product or a hack. Going down the route of something purely software, as we would have with our image processing concept, was a more viable option for this category of project, but we ultimately decided against it.

\begin{comment}
Do we want to talk about why we didn't go with the image processing project?
\end{comment}

Lastly, we discussed configuration-style tasks. The two proposals from team members were for a News Reader and for a SQL Helper. The core concept of the News Reader was that a user should be able to create custom queries that will obtain only the news that they are interested in, regardless of where the information was originally from. The idea behind the SQL Helper was to make SQL more accessible for the general public to use in everyday business situations; for example, a secretary with no prior SQL knowledge should be able to use it to get information from the company database to generate a report. We deemed the headache of building such a system while also making it robust enough to translate human queries into SQL to be too much work for the amount of time given for the project; so, we settled on the News Reader.

Every project needs a name; having selected our project, this was the most important task left to us. We settled on \textbf{D}ictation \textbf{E}valuation \textbf{R}eddit \textbf{P}arser because, if we have enough time, we'd like it to take spoken words as input to evaluate. The project will focus on interfacing with Reddit for a minimum viable product; however, the language is designed with other sources in mind.


\subsection{Why DERP}
DERP allows a developer to create an interface between a person and information feed sites such as \href{https://www.reddit.com}{Reddit}, \href{https://steemit.com/}{steemit}, \href{https://band.us/home}{BAND}, and \href{https://voat.co/}{Voat}, as described in the \hyperref[sec:whatisDERP]{What is DERP} section. This interface allows for a programmer to develop an application that cleanly links an end-user to the feed site(s) of their choice, without the user even being aware that they are using DERP. While developers who want to access new news sites will still need to know how to get information from the source site of their choosing, DERP is designed to do the heavy lifting of finding and sorting relevant data, allowing less technically-minded users to build their own information filters from existing sources. It is a free solution which can provide a consistent starting point for developers so that they do not need to worry about the details of determining what should be searched and how results should be organized.


\newpage
\section{DERP Design Goals}
\subsection{Consolidated Information}
The DERP project provides an intuitive way to multiplex groups of news sources into a personalized stream of data. Using DERP, a user can specify as many different sources as they want to (provided language plugins are available), and then all of those sources are accessed through the same set of language keywords, regardless of if the source is a subreddit, an arbitrary news website, or even just a file on the user's device. Furthermore, DERP facilitates naming groups of sources and queries to create criteria and new sources composed of other sources that can be used together, allowing users to further personalize what they get out of DERP.

Online news sources regularly expose the same categories of information - date, author, title, etc. DERP acts as an interface for all different article types, allowing users to work only with this high-level information about the articles they are finding. Hiding the details of what exactly is required to find an article that matches a specific criterion allows users to focus more on what they want to read, and less on how they obtain that information.

\subsection{Easy-to-Use Natural English Interface}
The second goal of DERP is to design a language that would not feel awkward if spoken. All of the DERP keywords and syntax follow simple but natural English speech patterns. This allows for easy adaptation of DERP into speech-recognition tools such as Google Assistant and Amazon Alexa. Using the natural form of the language, users with one of these devices could speak their program to the interpreter and receive results immediately.

In a similar vein, DERP provides output that also feels natural.
DERP has a set of phrases available to it for reporting errors or results from user queries. The main output from DERP, articles the user has requested, are outputted as full text so that, should devices reading them use a text-to-speech system, they will sound as natural as possible.

\subsection{Search More, Faster}
By merging news sources into a personalized feed, DERP allows users to find the information they want with fewer operations. Rather than check each of their favorite subreddits, news sites, and RSS feeds, a user can simply load those sources into DERP and make a general query that applies all of them at once. DERP will do the hard work of finding things the user might be interested in, which means the user will be able to spend more of their time actually consuming the information provided and deciding on new topics to get information about.

Because it is an extensible language, DERP's users are limited only by the language plugins they use. While some keywords are understood specially by the language, such as those pertaining to dates and times, any language plugin can provide additional fields and keywords, making the language flexible and powerful while keeping complexity out of it's core.


%%%%%%%%%%%%%%%%%%%%%%%%%%%% EXEC MODEL SECTION %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\section{\textbf{The DERP Execution Model}}
\input{interactive_exec_model.tex}
\input{hierarchical_exec_model.tex}
\input{constraints_exec_model.tex}

%%%%%%%%%%%%%%%%%%%%%%%%%%%% DQL SECTION %%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\section{\textbf{The DERP Query Language}}
The DERP Query Language (DERP-QL) makes it easy to write complex queries for a variety of Internet sources. In DERP, queries are represented by \textit{selections}. Selections find postings from a particular set of sources that match a corresponding set of criteria. The following is an example of a DERP-QL selection.

% Quotes in listings looks terrible
\begin{lstlisting}
Add posts from subreddit "nba" or subreddit "basketball" on "Lakers"
Remove posts with under 1000 upvotes
Remove posts on "Lebron James"
\end{lstlisting}

This selection does exactly what it says. It finds posts from \texttt{reddit.com/r/nba} or \\ \texttt{reddit.com/r/basketball} that don't involve Lebron James with 1000 upvotes or more.

\input{main_features_language.tex}
\input{primitives_language.tex}
\input{higher_order_types_language.tex}
\input{memory_management_language.tex}
\input{operators_language.tex}

\end{document}
